{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfw75uCr5QXP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn, cuda\n",
        "from torchvision import transforms,datasets\n",
        "from torch.utils.data import DataLoader,random_split\n",
        "import torch.nn as nn\n",
        "from math import ceil\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzEVqby95QXR"
      },
      "outputs": [],
      "source": [
        "!mkdir ./dataset \n",
        "data_dir = '../input/bird7z/Bird/train'\n",
        "classes = []\n",
        "img_per_class = []\n",
        "for folder in os.listdir(data_dir):    \n",
        "    classes.append(folder)\n",
        "    img_per_class.append(len(os.listdir(f'{data_dir}/{folder}')))\n",
        "num_classes = len(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-06T08:29:16.336782Z",
          "iopub.status.busy": "2022-06-06T08:29:16.336351Z",
          "iopub.status.idle": "2022-06-06T08:29:28.573674Z",
          "shell.execute_reply": "2022-06-06T08:29:28.572531Z",
          "shell.execute_reply.started": "2022-06-06T08:29:16.336702Z"
        },
        "trusted": true,
        "id": "QKwG0cHd5QXR"
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "    r\"\"\"Computes and stores the average and current value\n",
        "    \"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, *meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "    def print(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "        _, idx = output.sort(descending=True)\n",
        "        pred = idx[:,:maxk]\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-06T08:29:28.577580Z",
          "iopub.status.busy": "2022-06-06T08:29:28.576409Z",
          "iopub.status.idle": "2022-06-06T08:29:28.644596Z",
          "shell.execute_reply": "2022-06-06T08:29:28.643679Z",
          "shell.execute_reply.started": "2022-06-06T08:29:28.577534Z"
        },
        "trusted": true,
        "id": "s8h3VbQv5QXS"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "ReXNet\n",
        "Copyright (c) 2020-present NAVER Corp.\n",
        "MIT license\n",
        "\"\"\"\n",
        "\n",
        "USE_MEMORY_EFFICIENT_SiLU = True\n",
        "\n",
        "if USE_MEMORY_EFFICIENT_SiLU:\n",
        "    @torch.jit.script\n",
        "    def silu_fwd(x):\n",
        "        return x.mul(torch.sigmoid(x))\n",
        "\n",
        "\n",
        "    @torch.jit.script\n",
        "    def silu_bwd(x, grad_output):\n",
        "        x_sigmoid = torch.sigmoid(x)\n",
        "        return grad_output * (x_sigmoid * (1. + x * (1. - x_sigmoid)))\n",
        "\n",
        "\n",
        "    class SiLUJitImplementation(torch.autograd.Function):\n",
        "        @staticmethod\n",
        "        def forward(ctx, x):\n",
        "            ctx.save_for_backward(x)\n",
        "            return silu_fwd(x)\n",
        "\n",
        "        @staticmethod\n",
        "        def backward(ctx, grad_output):\n",
        "            x = ctx.saved_tensors[0]\n",
        "            return silu_bwd(x, grad_output)\n",
        "\n",
        "\n",
        "    def silu(x, inplace=False):\n",
        "        return SiLUJitImplementation.apply(x)\n",
        "\n",
        "else:\n",
        "    def silu(x, inplace=False):\n",
        "        return x.mul_(x.sigmoid()) if inplace else x.mul(x.sigmoid())\n",
        "\n",
        "\n",
        "class SiLU(nn.Module):\n",
        "    def __init__(self, inplace=True):\n",
        "        super(SiLU, self).__init__()\n",
        "        self.inplace = inplace\n",
        "\n",
        "    def forward(self, x):\n",
        "        return silu(x, self.inplace)\n",
        "\n",
        "\n",
        "def ConvBNAct(out, in_channels, channels, kernel=1, stride=1, pad=0,\n",
        "              num_group=1, active=True, relu6=False):\n",
        "    out.append(nn.Conv2d(in_channels, channels, kernel,\n",
        "                         stride, pad, groups=num_group, bias=False))\n",
        "    out.append(nn.BatchNorm2d(channels))\n",
        "    if active:\n",
        "        out.append(nn.ReLU6(inplace=True) if relu6 else nn.ReLU(inplace=True))\n",
        "\n",
        "\n",
        "def ConvBNSiLU(out, in_channels, channels, kernel=1, stride=1, pad=0, num_group=1):\n",
        "    out.append(nn.Conv2d(in_channels, channels, kernel,\n",
        "                         stride, pad, groups=num_group, bias=False))\n",
        "    out.append(nn.BatchNorm2d(channels))\n",
        "    out.append(SiLU(inplace=True))\n",
        "\n",
        "\n",
        "class SE(nn.Module):\n",
        "    def __init__(self, in_channels, channels, se_ratio=12):\n",
        "        super(SE, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, channels // se_ratio, kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(channels // se_ratio),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channels // se_ratio, channels, kernel_size=1, padding=0),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.avg_pool(x)\n",
        "        y = self.fc(y)\n",
        "        return x * y\n",
        "\n",
        "\n",
        "class LinearBottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, channels, t, stride, use_se=True, se_ratio=12,\n",
        "                 **kwargs):\n",
        "        super(LinearBottleneck, self).__init__(**kwargs)\n",
        "        self.use_shortcut = stride == 1 and in_channels <= channels\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = channels\n",
        "\n",
        "        out = []\n",
        "        if t != 1:\n",
        "            dw_channels = in_channels * t\n",
        "            ConvBNSiLU(out, in_channels=in_channels, channels=dw_channels)\n",
        "        else:\n",
        "            dw_channels = in_channels\n",
        "\n",
        "        ConvBNAct(out, in_channels=dw_channels, channels=dw_channels, kernel=3, stride=stride, pad=1,\n",
        "                  num_group=dw_channels, active=False)\n",
        "\n",
        "        if use_se:\n",
        "            out.append(SE(dw_channels, dw_channels, se_ratio))\n",
        "\n",
        "        out.append(nn.ReLU6())\n",
        "        ConvBNAct(out, in_channels=dw_channels, channels=channels, active=False, relu6=True)\n",
        "        self.out = nn.Sequential(*out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.out(x)\n",
        "        if self.use_shortcut:\n",
        "            out[:, 0:self.in_channels] += x\n",
        "\n",
        "        return out\n",
        "\n",
        "class ReXNetV1(nn.Module):\n",
        "    def __init__(self, input_ch=16, final_ch=180, width_mult=1.0, depth_mult=1.0, classes=400,\n",
        "                 use_se=True,\n",
        "                 se_ratio=12,\n",
        "                 dropout_ratio=0.20,\n",
        "                 bn_momentum=0.9):\n",
        "        super(ReXNetV1, self).__init__()\n",
        "\n",
        "        layers = [1, 2, 2, 3, 3, 5]\n",
        "        strides = [1, 2, 2, 2, 1, 2]\n",
        "        use_ses = [False, False, True, True, True, True]\n",
        "\n",
        "        layers = [ceil(element * depth_mult) for element in layers]\n",
        "        strides = sum([[element] + [1] * (layers[idx] - 1)\n",
        "                       for idx, element in enumerate(strides)], [])\n",
        "        if use_se:\n",
        "            use_ses = sum([[element] * layers[idx] for idx, element in enumerate(use_ses)], [])\n",
        "        else:\n",
        "            use_ses = [False] * sum(layers[:])\n",
        "        ts = [1] * layers[0] + [6] * sum(layers[1:])\n",
        "\n",
        "        self.depth = sum(layers[:]) * 3\n",
        "        stem_channel = 32 / width_mult if width_mult < 1.0 else 32\n",
        "        inplanes = input_ch / width_mult if width_mult < 1.0 else input_ch\n",
        "\n",
        "        features = []\n",
        "        in_channels_group = []\n",
        "        channels_group = []\n",
        "\n",
        "        # The following channel configuration is a simple instance to make each layer become an expand layer.\n",
        "        for i in range(self.depth // 3):\n",
        "            if i == 0:\n",
        "                in_channels_group.append(int(round(stem_channel * width_mult)))\n",
        "                channels_group.append(int(round(inplanes * width_mult)))\n",
        "            else:\n",
        "                in_channels_group.append(int(round(inplanes * width_mult)))\n",
        "                inplanes += final_ch / (self.depth // 3 * 1.0)\n",
        "                channels_group.append(int(round(inplanes * width_mult)))\n",
        "\n",
        "        ConvBNSiLU(features, 3, int(round(stem_channel * width_mult)), kernel=3, stride=2, pad=1)\n",
        "\n",
        "        for block_idx, (in_c, c, t, s, se) in enumerate(zip(in_channels_group, channels_group, ts, strides, use_ses)):\n",
        "            features.append(LinearBottleneck(in_channels=in_c,\n",
        "                                             channels=c,\n",
        "                                             t=t,\n",
        "                                             stride=s,\n",
        "                                             use_se=se, se_ratio=se_ratio))\n",
        "\n",
        "        pen_channels = int(1280 * width_mult)\n",
        "        ConvBNSiLU(features, c, pen_channels)\n",
        "\n",
        "        features.append(nn.AdaptiveAvgPool2d(1))\n",
        "        self.features = nn.Sequential(*features)\n",
        "        self.output = nn.Sequential(\n",
        "            nn.Dropout(dropout_ratio),\n",
        "            nn.Conv2d(pen_channels, classes, 1, bias=True))\n",
        "        \n",
        "    def extract_features(self, x):\n",
        "        return self.features[:-1](x)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.output(x).flatten(1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-06T08:29:28.645837Z",
          "iopub.status.busy": "2022-06-06T08:29:28.645572Z",
          "iopub.status.idle": "2022-06-06T08:29:31.701784Z",
          "shell.execute_reply": "2022-06-06T08:29:31.700822Z",
          "shell.execute_reply.started": "2022-06-06T08:29:28.645812Z"
        },
        "trusted": true,
        "id": "6Ub5RatC5QXX"
      },
      "outputs": [],
      "source": [
        "############################################################################\n",
        "model = ReXNetV1(width_mult=1.0, classes=400).cuda()\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.06)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5.77E-03, weight_decay=0.015)\n",
        "############################################################################\n",
        "\n",
        "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Number of parameters: {pytorch_total_params}\")\n",
        "if int(pytorch_total_params) > 5000000:\n",
        "    print('Your model has the number of parameters more than 5 millions..')\n",
        "    sys.exit()\n",
        "    \n",
        "device = torch.device('cuda:0' if cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-06T08:29:31.704438Z",
          "iopub.status.busy": "2022-06-06T08:29:31.704050Z",
          "iopub.status.idle": "2022-06-06T08:29:32.775219Z",
          "shell.execute_reply": "2022-06-06T08:29:32.774381Z",
          "shell.execute_reply.started": "2022-06-06T08:29:31.704401Z"
        },
        "trusted": true,
        "id": "A3thh6hd5QXY"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.RandomRotation((-15, 15)),\n",
        "                                      transforms.RandomRotation((-25, 25)),\n",
        "                                      transforms.RandomErasing(),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "data = datasets.ImageFolder(data_dir)\n",
        "train_size = int(len(data)*0.95)\n",
        "val_size = int((len(data)-train_size))\n",
        "train_data,val_data = random_split(data,[train_size,val_size])\n",
        "torch.manual_seed(3334)\n",
        "print(f'train size: {len(train_data)}\\nval size: {len(val_data)}')\n",
        "\n",
        "train_data.dataset.transform = train_transform\n",
        "val_data.dataset.transform = val_transform\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_data,batch_size=batch_size,shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-06T08:29:32.777137Z",
          "iopub.status.busy": "2022-06-06T08:29:32.776677Z",
          "iopub.status.idle": "2022-06-06T08:29:32.797033Z",
          "shell.execute_reply": "2022-06-06T08:29:32.796134Z",
          "shell.execute_reply.started": "2022-06-06T08:29:32.777099Z"
        },
        "trusted": true,
        "id": "bzy7_xuJ5QXY"
      },
      "outputs": [],
      "source": [
        "def fit(model,criterion,optimizer,num_epochs=10):\n",
        "    print_freq = 30\n",
        "    start = time.time()\n",
        "    train_loss_over_time = []\n",
        "    val_loss_over_time = []\n",
        "    train_acc_over_time = []\n",
        "    val_acc_over_time = []\n",
        "    best_model = model.state_dict()\n",
        "    best_acc = 0\n",
        "\n",
        "\n",
        "    # each epoch has a training and validation phase\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        print(\"\\n----- epoch: {}, lr: {} -----\".format(epoch, optimizer.param_groups[0][\"lr\"]))\n",
        "        batch_time = AverageMeter('Time', ':6.3f')\n",
        "        acc = AverageMeter('Accuracy', ':.4e')\n",
        "        progress = ProgressMeter(len(train_loader), batch_time, acc, prefix=\"Epoch: [{}]\".format(epoch))\n",
        "\n",
        "        for phase in ['train','val']:\n",
        "            \n",
        "            if phase == 'train':\n",
        "                data_loader = train_loader\n",
        "                model.train()                    # set the model to train mode\n",
        "                end = time.time()\n",
        "\n",
        "            else:\n",
        "                data_loader = val_loader\n",
        "                model.eval()                    # set the model to evaluate mode\n",
        "                end = time.time()\n",
        "            \n",
        "                \n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0.0\n",
        "            \n",
        "            # iterate over the data\n",
        "            for i,(inputs,labels) in enumerate(data_loader):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                # forward\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _,pred = torch.max(outputs,dim=1)\n",
        "                    loss = criterion(outputs,labels)\n",
        "                    \n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                \n",
        "                # calculating the loss and accuracy\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(pred == labels.data)\n",
        "\n",
        "                epoch_acc = (running_corrects.double()/len(train_data)).cpu().numpy()\n",
        "                acc.update(epoch_acc.item(), inputs.size(0))\n",
        "                \n",
        "                if phase == 'train':                          \n",
        "                    batch_time.update(time.time() - end)\n",
        "                    end = time.time()\n",
        "\n",
        "                    if i % print_freq == 0:\n",
        "                        progress.print(i)  \n",
        "\n",
        "            if phase == 'train':\n",
        "\n",
        "                epoch_loss = running_loss/len(train_data)\n",
        "                train_loss_over_time.append(epoch_loss)\n",
        "                epoch_acc = (running_corrects.double()/len(train_data)).cpu().numpy()\n",
        "                train_acc_over_time.append(epoch_acc)\n",
        "\n",
        "\n",
        "            else:\n",
        "                epoch_loss = running_loss/len(val_data)\n",
        "                val_loss_over_time.append(epoch_loss)\n",
        "                epoch_acc = (running_corrects.double()/len(val_data)).cpu().numpy()\n",
        "                val_acc_over_time.append(epoch_acc)\n",
        "          \n",
        "\n",
        "            print(f'{phase} loss: {epoch_loss:.3f}, acc: {epoch_acc:.3f}')\n",
        "            \n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                torch.save(model.state_dict(), 'model_best.pt')\n",
        "            \n",
        "            torch.save(model.state_dict(),'model_latest.pt')\n",
        "            \n",
        "        print('-'*60)\n",
        "    print('\\n') \n",
        "    elapsed_time = time.time() - start\n",
        "    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n",
        "    print(f'best accuracy: {best_acc:.3f}')\n",
        "\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model)\n",
        "    loss = {'train':train_loss_over_time, 'val':val_loss_over_time}\n",
        "    acc = {'train':train_acc_over_time, 'val':val_acc_over_time}\n",
        "\n",
        "    return model,loss, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-06T08:29:32.800589Z",
          "iopub.status.busy": "2022-06-06T08:29:32.799820Z",
          "iopub.status.idle": "2022-06-06T10:56:49.205785Z",
          "shell.execute_reply": "2022-06-06T10:56:49.204739Z",
          "shell.execute_reply.started": "2022-06-06T08:29:32.800555Z"
        },
        "trusted": true,
        "id": "2guNVBmu5QXZ"
      },
      "outputs": [],
      "source": [
        "epochs = 46\n",
        "history, loss, acc = fit(model, criterion, optimizer, num_epochs = epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcQPXgVC5QXZ"
      },
      "outputs": [],
      "source": [
        "train_loss = loss['train']\n",
        "val_loss = loss['val']\n",
        "train_acc = acc['train']\n",
        "val_acc = acc['val']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.ylim(0,10)\n",
        "plt.xlim(0,50)\n",
        "plt.plot(epochs_range, train_loss, label='train_loss')\n",
        "plt.plot(epochs_range, val_loss, label='val_loss')\n",
        "plt.legend(loc=0)\n",
        "plt.title('Loss')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs_range, train_acc ,label='train_acc')\n",
        "plt.plot(epochs_range, val_acc, label='val_acc')\n",
        "plt.legend(loc=0)\n",
        "plt.ylim(0,1)\n",
        "plt.xlim(0,50)\n",
        "plt.title('Accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-06T10:56:49.208091Z",
          "iopub.status.busy": "2022-06-06T10:56:49.207543Z",
          "iopub.status.idle": "2022-06-06T10:56:52.091678Z",
          "shell.execute_reply": "2022-06-06T10:56:52.090850Z",
          "shell.execute_reply.started": "2022-06-06T10:56:49.208045Z"
        },
        "trusted": true,
        "id": "2oymoEkG5QXa"
      },
      "outputs": [],
      "source": [
        "seed = 0\n",
        "torch.manual_seed(seed)\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "torch.manual_seed(3334)\n",
        "test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_data_dir = '../input/bird7z/Bird/test'\n",
        "_data = datasets.ImageFolder(test_data_dir)\n",
        "test1_size = int(len(_data)*1)\n",
        "test2_size = int((len(_data)-test1_size))\n",
        "test_data, test2_data = torch.utils.data.random_split(_data,[test1_size, test2_size])\n",
        "torch.manual_seed(3334)\n",
        "\n",
        "print(f'test size: {len(test_data)}')\n",
        "\n",
        "test_data.dataset.transform = test_transform\n",
        "batch_size = 256\n",
        "test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = False)\n",
        "print(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-06T11:04:18.556896Z",
          "iopub.status.busy": "2022-06-06T11:04:18.556549Z",
          "iopub.status.idle": "2022-06-06T11:04:18.728757Z",
          "shell.execute_reply": "2022-06-06T11:04:18.728020Z",
          "shell.execute_reply.started": "2022-06-06T11:04:18.556866Z"
        },
        "trusted": true,
        "id": "Ymzx4kcf5QXa"
      },
      "outputs": [],
      "source": [
        "model_Re = ReXNetV1(width_mult=1.0, classes=400, dropout_ratio = 0.16).cuda()\n",
        "model_Re.load_state_dict(torch.load('./model_best.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data.dataset.transform = new_transform\n",
        "batch_size = 128\n",
        "new_loader = DataLoader(val_data,batch_size=batch_size,shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "Pea-mVur6O1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-06T11:04:26.736914Z",
          "iopub.status.busy": "2022-06-06T11:04:26.736563Z",
          "iopub.status.idle": "2022-06-06T11:04:26.743140Z",
          "shell.execute_reply": "2022-06-06T11:04:26.742345Z",
          "shell.execute_reply.started": "2022-06-06T11:04:26.736886Z"
        },
        "trusted": true,
        "id": "ooUIpA3Z5QXa"
      },
      "outputs": [],
      "source": [
        "criterion_Re = nn.CrossEntropyLoss(label_smoothing=0.06)\n",
        "optimizer_Re = torch.optim.Adam(model_Re.parameters(),lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-06T11:04:31.103728Z",
          "iopub.status.busy": "2022-06-06T11:04:31.103152Z",
          "iopub.status.idle": "2022-06-06T11:05:12.541717Z",
          "shell.execute_reply": "2022-06-06T11:05:12.540677Z",
          "shell.execute_reply.started": "2022-06-06T11:04:31.103687Z"
        },
        "trusted": true,
        "id": "vIifuLhw5QXa"
      },
      "outputs": [],
      "source": [
        "for epoch in range(4):\n",
        "  model_Re.train() \n",
        "  for inputs,labels in val_loader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    optimizer_Re.zero_grad()\n",
        "    with torch.set_grad_enabled(True):\n",
        "      outputs = model_Re(inputs)\n",
        "      loss = criterion_Re(outputs,labels)\n",
        "      loss.backward()\n",
        "      optimizer_Re.step()\n",
        "torch.save(model_Re.state_dict(), 'model_final.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-06-06T11:05:12.543959Z",
          "iopub.status.busy": "2022-06-06T11:05:12.543641Z",
          "iopub.status.idle": "2022-06-06T11:05:18.857278Z",
          "shell.execute_reply": "2022-06-06T11:05:18.855714Z",
          "shell.execute_reply.started": "2022-06-06T11:05:12.543929Z"
        },
        "trusted": true,
        "id": "MzwNhHxw5QXb"
      },
      "outputs": [],
      "source": [
        "def evaluate_Re(model,criterion):\n",
        "    model.eval()       # setting the model to evaluate mode\n",
        "    preds = []\n",
        "    Category = []\n",
        "\n",
        "    test_model = ReXNetV1(width_mult=1.0, classes=400).cuda()\n",
        "\n",
        "    test_model.load_state_dict(torch.load('./model_final.pt'))\n",
        "    torch.save(test_model.state_dict(), './adam_001.pt')\n",
        "    \n",
        "    for inputs, label_ in test_loader:\n",
        "        \n",
        "        inputs = inputs.to(device)\n",
        "        labels = label_.to(device)\n",
        "        # predicting\n",
        "        with torch.no_grad():\n",
        "\n",
        "            outputs = test_model(inputs)\n",
        "            _,pred = torch.max(outputs,dim=1)\n",
        "            preds.append(pred)\n",
        "\n",
        "    category = [t.cpu().numpy() for t in preds]\n",
        "    \n",
        "    t_category = list(itertools.chain(*category))\n",
        "       \n",
        "    Id = list(range(0, len(t_category)))\n",
        "\n",
        "    prediction = {\n",
        "      'Id': Id,\n",
        "      'Category': t_category \n",
        "    }\n",
        "\n",
        "    prediction_df = pd.DataFrame(prediction, columns=['Id','Category'])\n",
        "    #저장경로는 변경하셔도 됩니다.\n",
        "    prediction_df.to_csv('./adam_001.csv', index=False)\n",
        "    \n",
        "    print('Done!!!!')\n",
        "        \n",
        "    return preds\n",
        "\n",
        "# testing the model\n",
        "predictions = evaluate_Re(model_Re, criterion_Re)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "name": "Team5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}